# **Proyecto de Ayuda DANA Valencia - README**

## üìã **Descripci√≥n del Proyecto**
El objetivo de este proyecto es crear una plataforma que conecte a personas afectadas por la DANA de Valencia con voluntarios dispuestos a ayudar. La aplicaci√≥n permite tanto solicitar como ofrecer ayuda mediante una interfaz sencilla desarrollada con Streamlit. Utiliza Google Cloud Platform como infraestructura principal para procesar, emparejar y almacenar los datos.

El sistema empareja autom√°ticamente las solicitudes de ayuda con voluntarios cercanos bas√°ndose en la ubicaci√≥n geogr√°fica, categor√≠a de ayuda y nivel de urgencia, optimizando as√≠ la distribuci√≥n de recursos y acelerando el tiempo de respuesta.

Aunque este proyecto se dise√±√≥ inicialmente para asistir a las personas afectadas por la DANA en Valencia, su arquitectura en la nube permite su implementaci√≥n y uso en cualquier parte del mundo, adapt√°ndose a diversas situaciones de emergencia.

## ‚öôÔ∏è **Funcionalidades Principales**
- **Solicitud de Ayuda**: Formulario para personas afectadas por la DANA
- **Oferta de Voluntariado**: Formulario para voluntarios que desean ayudar
- **Matching Autom√°tico**: Emparejamiento basado en ubicaci√≥n, categor√≠a y urgencia
- **Algoritmo de Distancia**: C√°lculo mediante f√≥rmula de Haversine para encontrar voluntarios cercanos
- **Procesamiento en Tiempo Real**: Pipeline de datos con Apache Beam en Dataflow
- **Almacenamiento de Datos**: Registro de solicitudes, voluntarios y emparejamientos en BigQuery
- **Visualizaci√≥n**: Dashboard en Grafana para seguimiento de m√©tricas clave
- **Infraestructura como C√≥digo**: Despliegue automatizado con Terraform

## üèóÔ∏è **Arquitectura del Sistema**


![arquitectura](https://github.com/user-attachments/assets/9b51ea04-aa58-4c69-b663-acaf667ad9e4)



## üîÑ **Flujo de Datos**

1. El usuario rellena un formulario en la aplicaci√≥n Streamlit (pedir_ayuda.py o ofrecer_ayuda.py)
2. Los datos se env√≠an a Pub/Sub a trav√©s de temas espec√≠ficos para ayuda y voluntarios
3. Dataflow (dataflow.py) procesa los mensajes utilizando Apache Beam:
   - Lee mensajes de las suscripciones de Pub/Sub
   - Agrupa los datos por categor√≠a
   - Realiza el matching utilizando el algoritmo de distancia (haversine)
   - Env√≠a los matches exitosos a BigQuery
   - Reintenta hasta 5 veces los mensajes no emparejados
   - Almacena en BigQuery los mensajes que no pudieron ser emparejados despu√©s de 5 intentos
4. Los resultados se almacenan en BigQuery en diferentes tablas:
   - matched_pairs: Emparejamientos exitosos
   - unmatched_requests: Solicitudes de ayuda no emparejadas
   - unmatched_volunteers: Ofertas de voluntarios no emparejadas
5. Grafana se conecta a BigQuery para mostrar dashboards actualizados

## üßÆ **Algoritmo de Matching**

El sistema utiliza el algoritmo de Haversine para calcular la distancia entre solicitantes y voluntarios. El proceso es:

1. Se ordenan las solicitudes de ayuda por nivel de urgencia (de mayor a menor)
2. Para cada solicitud, se busca el voluntario m√°s cercano dentro de su radio de disponibilidad
3. Se crea un emparejamiento cuando se encuentra un voluntario adecuado
4. Los voluntarios ya emparejados no est√°n disponibles para otras solicitudes en ese ciclo

## üõ†Ô∏è **Requisitos Previos**
1. Python 3.8+
2. Cuenta de Google Cloud Platform con facturaci√≥n habilitada
3. Google Cloud SDK instalado y configurado
4. Terraform (para despliegue de infraestructura)

## üöÄ **C√≥mo Ejecutar el Proyecto**

### 1. Clonar el repositorio

```bash
git clone https://github.com/joel1091/Data-Project-2.git
cd Data-Project-2
```

### 2. Iniciar sesi√≥n Google Cloud CLI

```
gcloud auth login
gcloud config set project dataproject2425
gcloud config set compute/region europe-west1
```

### 3. Desplegar infraestructura con Terraform

```bash
cd terraform
terraform init
terraform plan
terraform apply
```

### 4. Acceder a Streamlit
Para poder enviar mensajes manualmente, accede a streamlit ejecutando el siguiente comando:
```
gcloud run services list --platform managed --region¬†europe-west1
```
Ahora haz click en el link que te proporciona el service `Streamlit`

## üìÅ **Archivos Clave**

| Archivo | Descripci√≥n |
|---------|-------------|
| terraform/main.tf | Configuraci√≥n principal de la infraestructura |
| Dataflow/dataflow.py | Pipeline de procesamiento de datos |
| Streamlit/app.py | Plataforma para solicitar o pedir ayuda |
| app/automatic/main.py | Generador autom√°tico de voluntarios y necesitados |


## üìä **Tablas en BigQuery**

### matched_pairs
- match_id (STRING): Identificador √∫nico del emparejamiento
- categoria (STRING): Categor√≠a de ayuda
- distance (FLOAT): Distancia en km entre solicitante y voluntario
- urgencia (INTEGER): Nivel de urgencia de la solicitud
- help_* (varios campos): Informaci√≥n del solicitante
- volunteer_* (varios campos): Informaci√≥n del voluntario

### unmatched_requests
- id (STRING): Identificador √∫nico de la solicitud
- nombre, ubicacion, poblacion, categoria, descripcion (STRING)
- created_at (TIMESTAMP): Fecha de creaci√≥n
- nivel_urgencia (INTEGER): Prioridad de la solicitud
- telefono (STRING): Contacto del solicitante
- attempts (INTEGER): N√∫mero de intentos de emparejamiento
- insertion_stamp (TIMESTAMP): Fecha de inserci√≥n en BigQuery

### unmatched_volunteers
- id (STRING): Identificador √∫nico del voluntario
- nombre, ubicacion, poblacion, categoria (STRING)
- radio_disponible_km (INTEGER): Distancia m√°xima que puede cubrir
- created_at (TIMESTAMP): Fecha de creaci√≥n
- attempts (INTEGER): N√∫mero de intentos de emparejamiento
- insertion_stamp (TIMESTAMP): Fecha de inserci√≥n en BigQuery

## üìä **Monitorizaci√≥n**

El proyecto incluye un dashboard en Grafana que muestra:
- N√∫mero total de mensajes recibidos.
- N√∫mero total de matches realizados.
- Categor√≠as m√°s solicitadas/ofrecidas.
- N√∫mero de matches por localizaci√≥n y por categor√≠a.
- √∫mero de peticiones sin coincidencia por localizaci√≥n y categor√≠a.

### Para acceder a Grafana, sigue los siguientes pasos:
1. Ejecuta este comando y accede al link proporcionado (Service: Grafana)
```bash
gcloud run services list --platform managed --region¬†europe-west1
```
2. Inicia sesi√≥n: 
               <br>
               User: `admin` 
               <br>
               Password: `dataproject2`

3. A√±ade el conector en `Connections` > `Add new connection`

4. Selecciona `Google BigQuery` y haz click en `Install`
   
5. Haz click en `Add new data source` 
   
6. Selecciona abajo `GCE Default Service Account` y escriba el nombre del proyecto `dataproject2425`
   
7. Dir√≠gete a `Dashboards` 
   
8. Haz click en `New` y en `Import` 
   
9.  Importa el archivo json: [dashboard-grafana.json](Grafana/dashboard-grafana.json)
    
10. Selecciona `Google BigQuery data source`

</br>

![Grafana-Dashboard](Grafana/Grafana_dashboard.png)

## üîß **Tecnolog√≠as Utilizadas**

| Tecnolog√≠a | Uso |
|------------|-----|
| Google Cloud Platform | Infraestructura en la nube |
| Pub/Sub | Mensajer√≠a en tiempo real |
| Dataflow | Procesamiento de datos |
| BigQuery | Almacenamiento y an√°lisis de datos |
| Grafana | Visualizaci√≥n y monitoreo |
| Streamlit | Interfaz de usuario |
| Apache Beam | Framework de procesamiento |
| Terraform | Infraestructura como c√≥digo |
| Docker | Contenerizaci√≥n |
| Python | Lenguaje de programaci√≥n |

## üé• Demostraci√≥n en Video

[Accede desde aqu√≠ al video de la demostraci√≥n de la app](https://youtu.be/FMXI984ecq0) 

```bash
https://youtu.be/FMXI984ecq0
```

## ü§ù **Contribuciones**

Para contribuir:
1. Crea una nueva rama (`git checkout -b feature/amazing-feature`)
2. Realiza tus cambios
3. Haz commit de tus cambios (`git commit -m 'Add some amazing feature'`)
4. Push a la rama (`git push origin feature/amazing-feature`)
5. Abre un Pull Request

## üìÑ **Licencia**

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

## üìû **Proyecto hecho por Ting, Joel y Alejandro**

Ting - [Github](https://github.com/e-wach)
 | Joel - [GitHub](https://github.com/joel1091)
 | Alejandro - [Github](https://github.com/Alejbc27) 


Link del proyecto: [https://github.com/joel1091/Data-Project-2](https://github.com/joel1091/Data-Project-2)

